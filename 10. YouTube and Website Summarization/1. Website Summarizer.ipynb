{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170019ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import validators\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "\n",
    "import os\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c504a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the groq API key from .env file\n",
    "dotenv.load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f89045",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Gemma Model\n",
    "llm = ChatGroq(groq_api_key=groq_api_key, model=\"Gemma2-9b-It\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc2d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prompt Template\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Provide a summary of the following content in 300 words:\n",
    "Content: {text}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8a853d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adity\\Desktop\\GEN AI\\.venv\\lib\\site-packages\\magic\\magic.py:201: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if result is -1:\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\adity\\Desktop\\GEN AI\\.venv\\lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'docs.smith.langchain.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.19s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/'}, page_content=\"Get started with LangSmith\\n\\nLangSmith is a platform for building production-grade LLM applications. It allows you to closely monitor and evaluate your application, so you can ship quickly and with confidence.\\n\\n\\n\\nObservability\\n\\nAnalyze traces in LangSmith and configure metrics, dashboards, alerts based on these.\\n\\nEvals\\n\\nEvaluate your application over production traffic — score application performance and get human feedback on your data.\\n\\nPrompt Engineering\\n\\nIterate on prompts, with automatic version control and collaboration features.\\n\\nLangSmith + LangChain OSS\\n\\nLangSmith is framework-agnostic — it can be used with or without LangChain's open source frameworks langchain and langgraph.\\n\\nIf you are using either of these, you can enable LangSmith tracing with a single environment variable. For more see the how-to guide for setting up LangSmith with LangChain or setting up LangSmith with LangGraph.\\n\\nObservability\\u200b\\n\\nObservability is important for any software application, but especially so for LLM applications. LLMs are non-deterministic by nature, meaning they can produce unexpected results. This makes them trickier than normal to debug.\\n\\nThis is where LangSmith can help! LangSmith has LLM-native observability, allowing you to get meaningful insights from your application. LangSmith’s observability features have you covered throughout all stages of application development - from prototyping, to beta testing, to production.\\n\\nGet started by adding tracing to your application.\\n\\nCreate dashboards to view key metrics like RPS, error rates and costs.\\n\\nEvals\\u200b\\n\\nThe quality and development speed of AI applications depends on high-quality evaluation datasets and metrics to test and optimize your applications on. The LangSmith SDK and UI make building and running high-quality evaluations easy.\\n\\nGet started by creating your first evaluation.\\n\\nQuickly assess the performance of your application using our off-the-shelf evaluators as a starting point.\\n\\nAnalyze results of evaluations in the LangSmith UI and compare results over time.\\n\\nEasily collect human feedback on your data to improve your application.\\n\\nPrompt Engineering\\u200b\\n\\nWhile traditional software applications are built by writing code, AI applications involve writing prompts to instruct the LLM on what to do. LangSmith provides a set of tools designed to enable and facilitate prompt engineering to help you find the perfect prompt for your application.\\n\\nGet started by creating your first prompt.\\n\\nIterate on models and prompts using the Playground.\\n\\nManage prompts programmatically in your application.\\n\\nWas this page helpful?\\n\\nYou can leave detailed feedback on GitHub.\\n\\nObservability\\n\\nEvals\\n\\nPrompt Engineering\")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = input(\"Enter a URL to summarize: \")\n",
    "\n",
    "if not validators.url(url):\n",
    "    print(\"Invalid URL. Please enter a valid URL.\")\n",
    "else:\n",
    "    loader = UnstructuredURLLoader(urls=[url], ssl_verify=False,\n",
    "                                    show_progress_bar=True,\n",
    "                                    continue_on_failure=False,\n",
    "                                    headers={\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 13_5_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\"}\n",
    "                                )\n",
    "    docs = loader.load()\n",
    "\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2b5cdf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2690"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "912a2dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Local\\Temp\\ipykernel_15736\\3780381166.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  summary = chain.run(docs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"LangSmith is a platform designed to streamline the development and deployment of production-ready AI applications powered by Large Language Models (LLMs).  \\n\\nIt offers three key features:\\n\\n**Observability:** LangSmith provides deep insights into your LLM application's performance. You can trace requests, configure dashboards with essential metrics (like request per second, error rates, and costs), and set up alerts for critical issues. This LLM-specific observability helps you understand and debug the often unpredictable nature of LLMs.\\n\\n**Evals:** LangSmith simplifies the process of evaluating your AI application's quality. It allows you to build and run evaluations using pre-built metrics or custom ones. You can analyze results, track performance over time, and even gather human feedback to continually improve your application.\\n\\n**Prompt Engineering:** Since AI applications rely on well-crafted prompts to guide the LLM, LangSmith offers tools to streamline this process.  You can create, manage, and iterate on prompts within the platform, experimenting with different variations and leveraging the Playground for testing and refinement.\\n\\nFurthermore, LangSmith is framework-agnostic, meaning it can be used with or without popular open-source frameworks like LangChain and LangGraph. This flexibility makes it a versatile tool for developers building a wide range of LLM applications.  \\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt)\n",
    "summary = chain.run(docs)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15ad8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
