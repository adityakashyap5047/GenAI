{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d947fb73",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')    ### For LangSmith Tracking\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'  ### For LangSmith Tracking\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')  ### For LangSmith Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc076c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001B977CE4850> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001B977CE73A0> root_client=<openai.OpenAI object at 0x000001B976CE2A70> root_async_client=<openai.AsyncOpenAI object at 0x000001B977CE48B0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "331e15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7456fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a category of artificial intelligence systems designed to generate new content, such as text, images, music, or code, often by learning patterns from existing data. These systems use models like Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), and transformer-based architectures like GPT (Generative Pre-trained Transformers). \\n\\nThe core idea is to train models on large datasets so they can create outputs that mimic the input data in creative or useful ways. For example, they can produce natural language responses (as in chatbots), create art, simulate realistic human faces, compose music, or generate code. Generative AI has applications across various fields, including entertainment, design, and even healthcare, for tasks like drug discovery or creating personalized medicine.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 159, 'prompt_tokens': 13, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276', 'id': 'chatcmpl-BTpS0izAH4VhFdM400i8ISLa3P0mv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--2e8f259a-324b-47cd-b4b1-0ef80cc813a9-0' usage_metadata={'input_tokens': 13, 'output_tokens': 159, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35311f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
