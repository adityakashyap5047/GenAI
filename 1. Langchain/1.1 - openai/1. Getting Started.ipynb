{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d947fb73",
   "metadata": {},
   "source": [
    "#### Getting started With Langchain And Open AI\n",
    "\n",
    "In this quickstart we'll see how to:\n",
    "\n",
    "- Get setup with LangChain, LangSmith and LangServe\n",
    "- Use the most basic and common components of LangChain: prompt templates, models, and output parsers.\n",
    "- Build a simple application with LangChain\n",
    "- Trace your application with LangSmith\n",
    "- Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fec261c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGCHAIN_API_KEY'] = os.getenv('LANGCHAIN_API_KEY')    ### For LangSmith Tracking\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'  ### For LangSmith Tracking\n",
    "os.environ['LANGCHAIN_PROJECT'] = os.getenv('LANGCHAIN_PROJECT')  ### For LangSmith Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc076c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000013482FA8220> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000013482FAAF80> root_client=<openai.OpenAI object at 0x00000134FEFFF670> root_async_client=<openai.AsyncOpenAI object at 0x0000013482FA82E0> model_name='gpt-4o' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "331e15bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input and get response from LLM\n",
    "\n",
    "result = llm.invoke(\"What is generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7456fdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Generative AI refers to a subset of artificial intelligence that focuses on creating new content, such as text, images, music, or other media, that is similar to human-created content. This type of AI uses models and algorithms, particularly those involving machine learning and deep learning, to generate data that mimics existing patterns found in the input dataset.\\n\\nKey technologies in generative AI include:\\n\\n1. **Generative Adversarial Networks (GANs):** These consist of two neural networks, a generator and a discriminator, that work against each other. The generator creates new data instances, while the discriminator evaluates them. The goal is to improve the generator's ability to create data that is indistinguishable from real data.\\n\\n2. **Variational Autoencoders (VAEs):** These are used for generating new, similar data points. They work by encoding input data into a smaller, dense representation, and then decoding it back to original dimensions, while learning meaningful representations of the input data.\\n\\n3. **Transformers:** This architecture is particularly famous for state-of-the-art natural language processing tasks. Models like GPT (Generative Pre-trained Transformer) use large datasets to generate text that is coherent and contextually relevant.\\n\\nGenerative AI has a wide range of applications, including:\\n\\n- **Text Generation:** Producing articles, reports, and creative writing.\\n- **Image and Video Synthesis:** Creating realistic photos or videos, enhancing image resolution, or altering video elements.\\n- **Music Composition:** Generating original music compositions based on learned styles.\\n- **Drug Discovery:** Generating potential new drug compounds for medical research.\\n- **Style Transfer and Art:** Creating art by applying specific styles to content using AI.\\n\\nThe advancements in generative AI have raised both excitement and concerns regarding creativity, authenticity, ethical use, and the potential for misuse.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 368, 'prompt_tokens': 13, 'total_tokens': 381, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BmFzaNkOmviZyl0Y0Ok3ClwBQ1sYq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--ebd57ff3-7e8f-4aa2-bfe7-21fa00969ab2-0' usage_metadata={'input_tokens': 13, 'output_tokens': 368, 'total_tokens': 381, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b35311f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the questions.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chatprompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI Engineer. Provide me answers based on the questions.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ebeeb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm    ### The 'or' here will do is that we need to combine prompt along with LLM and that becomes a chain. and whenever we call the chain, it will call the prompt and then LLM.\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da13b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Langsmith is a platform developed by LangChain that provides a suite of tools designed to assist developers in building, testing, and optimizing applications that use large language models (LLMs). It enables developers to efficiently prototype applications by transforming standalone LLM prompts into integrated applications with advanced language model capabilities. Some of the core features of Langsmith include:\\n\\n1. **Debugging & Testing**: Langsmith allows developers to monitor and troubleshoot their LLM-powered applications by tracking requests and responses. This helps in understanding how models interact with inputs and how they can be improved.\\n\\n2. **Evaluation**: The platform offers tools to evaluate the performance of language models, considering various metrics to ensure the application meets desired outcomes.\\n\\n3. **Tracing**: With Langsmith, developers can record and trace how information flows through their applications, helping them optimize pipelines and workflows for better efficiency and effectiveness.\\n\\n4. **Feedback Integration**: It integrates tools for collecting user feedback within the language applications, which can then be used to refine and enhance the model's performance.\\n\\nOverall, Langsmith is designed to streamline the development process of LLM-powered applications by providing robust tools for debugging, evaluation, and real-time performance monitoring, making it easier for developers to achieve higher-quality and more reliable language applications.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 254, 'prompt_tokens': 33, 'total_tokens': 287, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_07871e2ad8', 'id': 'chatcmpl-BmFzkfyFfgwdCxlyBlqPH1Z2rUdKE', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--6efb5842-3f2a-4cc2-806a-718ead7959e2-0', usage_metadata={'input_tokens': 33, 'output_tokens': 254, 'total_tokens': 287, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49782646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3806df81",
   "metadata": {},
   "outputs": [],
   "source": [
    "### stroutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()   #### This is used to parse the output from the LLM and convert it into a string format.\n",
    "\n",
    "chain = prompt|llm|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"Can you tell me about Langsmith\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59325ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Langsmith is a tool associated with LangChain, a popular framework designed for building applications with large language models (LLMs). Langsmith focuses on the development, testing, and evaluation of LLM applications, which is crucial for improving the reliability and performance of these models. It offers features such as tracing and debugging to enhance the efficiency of the development process, making it easier to monitor model interactions and identify issues. Langsmith also provides facilities for evaluating models to ensure they meet desired performance metrics. It can be used both as a SaaS (Software as a Service) through LangChain's platform or deployed self-hosted for more control and customization.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665e836",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
